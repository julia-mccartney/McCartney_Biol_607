---
author: "Julia"
date: "11/23/2020"
output: html_document
---
# Homework 8: GLM Practice {.tabset}

#### Julia McCartney  
#### Due 11/27/2020

This homework's file can also be found on [Github]()

  
Libraries Used
```{r Libraries, message=FALSE}
library(readr)
library(ggplot2)
library(emmeans)
library(dplyr)
library(car)
library(brms)
library(loo)
library(tidybayes)
library(ggdist)
```


## 1. Comparing Means

To start with, let’s warm up with a simple one-way ANOVA model. This example, from Whitlock and Schluter chapter 15 question 22 looks at the mass of lodgepole pinecones from different habitats.



#### 1.1 Load and plot the data. 
Choose a plot that not only shows the raw data, but also the means and SE or CI of those means. +1 EC if Michael thinks it’s fancy.

Importing Data
```{r 1.1 load data}
pinecone <- read_csv("https://www.zoology.ubc.ca/~whitlock/ABD/teaching/datasets/15/15q22LodgepolePineCones.csv", col_types = "fd")
```


```{r 1.1 graphing data}
# graph the pinecone data
ggplot(data = pinecone,
       aes(x = habitat, y = conemass)) +
  geom_point() +
  stat_summary( alpha = 0.5, color = "blue") +
  labs(x = "Habitat",
       y = "Cone Mass") +
  theme_classic()

```




#### 1.2 Fit a model using least squares and evaluate all relevant assumptions. 
List them out as you test them. Can we use this model? If not, fix it. But if we can, no fix is needed!

```{r 1.2 ls model, warning = FALSE}
# fit a ls model
pinecone_lm <- lm(conemass ~ habitat, data = pinecone)

#test assumptions
plot(pinecone_lm, which = c(1,2,4,5)) # all look good, no major outliers and no relationship between residuals

car::residualPlots(pinecone_lm) # Residuals looks consistent across habitat type 
```
The assumptions are met, this model can be used!

#### 1.3 How much variation is explained by your model?

```{r 1.3 variation}
# Anova
car::Anova(pinecone_lm)

# r squared
summary(pinecone_lm)
```

The model explains 88.51% of the variation.

#### 1.4 Show which means are different from each other. 
Are you correcting p-values? If so, how, and justify your choice.

As there are few comparisons happening, (and thus low risk of false significant p-values) I will not be using a p-value correction

```{r 1.4}
# calculate means
pinecone_em <- emmeans(pinecone_lm, ~habitat)

# Calculate post hoc Tukey

contrast(pinecone_em,
         method = "tukey",
         adjust = "none")
```

There are differences between habitats with and without islands, as well as between habitats without islands and with mainlands. However, there is not a significant difference between cone maps between habitats with islands and with mainlands. 


## 2. Comparing Means from Multiple Categories

In a study from Rogers et al. (2020) link, the authors performed an experiment where they moved panels that had been colonized by invertebrates on a dock to a nearby rocky jetty where predators could access panels. To separate out the effects of changes in abiotic environment versus predation, they performed a factorial experiment, either caging or not caging panels and placing them either on the side of a cinder block or hanging on a piece of PVC attached to the block where predators would have little access (but weren’t entirely stopped). They then looked at change in total cover of invertebrates. Using this old data file dug off of my hard drive, let’s see what they found.

#### 2.1 Load and plot the data. 
We are interested in change in percent cover. Choose a plot that not only shows the raw data, but also the means and SE or CI of those means. +1 EC if Michael thinks it’s fancy.

```{r 2.1 load data}
# Import Data
invert <- read_csv("../data/fouling_transplant_data.csv", col_types = "cffddddddddddddd")

str(invert)
```


```{r 2.1 graph}
# graph the data
ggplot(data = invert,
       aes(fill = `Position On Block`, y = `Change in Cover`, x = Caged)) +
  geom_boxplot() +
  theme_classic()

```

It looks like we may have an interaction.

#### 2.2 Fit a model using likelihood and evaluate all relevant assumptions. 
Do you meet assumptions?

```{r 2.2 likelihood model}
# likelihood model
invert_glm <- glm(`Change in Cover` ~ `Position On Block`*Caged,
                  data = invert,
                  family = gaussian(link = "identity"))

# assumptions
plot(invert_glm, which = c(1,2,4,5))
car::residualPlots(invert_glm)
```

All assumptions look good! there is no relationship between residuals and fitted values across all factor levels, no obvious outliers are seen, and the qqplot looks fairly normal. 


#### 2.3 If you answered yes to the above…. you are wrong. 

oh.

It doesn’t! Percentage data is weird. Difference in percentages can be ever weirder! There are three tried and true solutions here. But they MIGHT not all work.

 - Incorporate initial cover as a covariate. This takes out that influence, and as such we’re looking at residuals of change. This sometimes, but not always, works.

 - Divide change by initial cover to express change as percent change relative to initial cover.

 - Calculate difference in logit cover (so, logist(initial cover) - logit(final cover)). Logit transformations linearize percent cover data, and are often all that is needed to work percent cover into a linear model. You can use car::logit() for this.

Try all three methods. Which one works so that you can produce valid inference?

```{r 2.3 I was wrong}

# Solution 1
invert_glm_sl1 <- glm(`Change in Cover` ~ `Position On Block`*Caged + `Initial Cover`,
                  data = invert,
                  family = gaussian(link = "identity"))

plot(invert_glm_sl1, which = c(1,2,4,5))
car::residualPlots(invert_glm_sl1) # only getting one boxplot :(

invert_sl1 <- invert %>% 
  modelr::add_residuals(invert_glm_sl1) 

#do it by hand
ggplot(invert_sl1,
       aes(x = Caged, y = resid)) + 
  geom_boxplot() # reids do not vary by group

#do it by hand
ggplot(invert_sl1,
       aes(x = `Position On Block`, y = resid)) + 
  geom_boxplot() # reids do not vary by group

# It still looks like assumptions are met (but how do I know it doesn't work?)

# Solution 2
invert <- invert %>% 
  mutate(change_div_initial = `Change in Cover` / `Initial Cover`)

invert_glm_sl2 <- glm(change_div_initial ~ `Position On Block`*Caged,
                  data = invert,
                  family = gaussian(link = "identity"))

plot(invert_glm_sl2, which = c(1,2,4,5))
car::residualPlots(invert_glm_sl2)

invert_sl2 <- invert %>% 
  modelr::add_residuals(invert_glm_sl2) 

#do it by hand
ggplot(invert_sl2,
       aes(x = Caged, y = resid)) + 
  geom_boxplot() 

#do it by hand
ggplot(invert_sl2,
       aes(x = `Position On Block`, y = resid)) + 
  geom_boxplot() 
#NOPE LOOKS LIKE HOT GARBAGE

# Solution 3
invert <- invert %>% 
  mutate(logit = car::logit(`Initial Cover`) - car::logit(`Final Cover`))

invert_glm_sl3 <- glm(logit ~ `Position On Block`*Caged,
                  data = invert,
                  family = gaussian(link = "identity"))

plot(invert_glm_sl3, which = c(1,2,4,5))
car::residualPlots(invert_glm_sl3)

invert_sl3 <- invert %>% 
  modelr::add_residuals(invert_glm_sl3) 

#do it by hand
ggplot(invert_sl3,
       aes(x = Caged, y = resid)) + 
  geom_boxplot() 

#do it by hand
ggplot(invert_sl3,
       aes(x = `Position On Block`, y = resid)) + 
  geom_boxplot() 

#looks except for plot of pearson resids to linear predictor

```

The second solution seemed to preform the worst (and given the output of residualPlots(), I really wouldn't trust that solution). The assumptions for both the 1st and 3rd solutions look ok, but the 1st looks the best.


#### 2.4 Great! So, take us home! 
Using NHST with an alpha of 0.08 (why not), what does this fit model tell you about whether predation matters given how I have described the system? Feel free to replot the data or fit model results if helpful

```{r 2.4}
# Anova
Anova(invert_glm_sl1)
Anova(invert_glm_sl3)

# post hoc
invert_sl1_em <- emmeans(invert_glm_sl1, ~  `Position On Block` + Caged)
invert_sl3_em <- emmeans(invert_glm_sl3, ~ `Position On Block` + Caged)

contrast(invert_sl1_em, method = "tukey")
contrast(invert_sl3_em, method = "tukey")

# no interaction
invert_glm_sl1_noint <- glm(`Change in Cover` ~ `Position On Block` + Caged + `Initial Cover`,
                  data = invert,
                  family = gaussian(link = "identity"))

invert_glm_sl3_noint <- glm(logit ~ `Position On Block` + Caged,
                  data = invert,
                  family = gaussian(link = "identity"))

# post hoc
invert_sl1_nointem <- emmeans(invert_glm_sl1_noint, ~ `Position On Block` + Caged)
invert_sl3_nointem <- emmeans(invert_glm_sl3_noint, ~ `Position On Block` + Caged)

contrast(invert_sl1_nointem, method = "tukey")
contrast(invert_sl3_nointem, method = "tukey")


```


By both the first and third adjustments made to the model, the position on the block and whether the system was caged or not had a significant impact on predation (p < 0.08). Following a post-hoc Tukey test, there were no significant differences between treatments with the same position, but there were significant differences between treatments that were either both caged or uncaged. While caging still had a significant impact on predation, it appears that the position of the panel had a more dominant effect. Positioning the panels so they were less accessible to predators

There is no interaction between cages. 


## 3. Comparing Means with Covariates

We will wrap up with a model mixing continuous and discrete variables. In this dataset from Scantlebury et al, the authors explored how caste and mass affected the energy level of naked mole rats.

#### 3.1 OK, you know what you are about at this point. 
Load in the data, plot it, fit it, check assumptions. Use Bayes for this.

```{r 3.1 load data, message = FALSE}
# read in the data
mole <- read_csv("https://www.zoology.ubc.ca/~whitlock/ABD/teaching/datasets/18/18e4MoleRatLayabouts.csv", col_types = "fdd")
```

```{r 3.1 plot}
# plot the data
mole_plot <- ggplot(data = mole,
       aes(y = lnenergy, x = lnmass, color = caste)) +
  geom_point() +
  theme_classic()

mole_plot +
  stat_smooth(method = "lm")
```

Looking at this, it seems like we may have an interaction?

```{r 3.1 baysian fit!, message=FALSE}
# fit an interaction and non-interaction model
mole_brm <- brm(lnenergy ~ lnmass + caste,
                data = mole,
                family = gaussian(link = "identity"))
mole_brm_int <- brm(lnenergy ~ lnmass*caste,
                data = mole,
                family = gaussian(link = "identity"))

# check assumptions 

# non-int first
# The chains and posteriors look good
plot(mole_brm)

# Rhat values look like they are very close to 1
bayesplot::mcmc_rhat(rhat(mole_brm))

# No issues with autocorrelation here!
bayesplot::mcmc_acf(as.data.frame(mole_brm))

# Model assumptions
bayes_fit <- fitted(mole_brm) %>%  as.data.frame()
bayes_res <- residuals(mole_brm) %>%  as.data.frame()

# Doesn't seem like there is any relationship
qplot(bayes_fit$Estimate, bayes_res$Estimate)

# ok
pp_check(mole_brm, type = "scatter")

# A little off at the tails but otherwise ok
qqnorm(bayes_res$Estimate)
qqline(bayes_res$Estimate)

# but the error looks normal
pp_check(mole_brm, type = "error_hist")

# Chains fit to posterior and data well
pp_check(mole_brm, type = "stat_2d", test = c("mean", "sd"))
pp_check(mole_brm)

# Assumptions of the model are met!

# int model next #######################

# The chains and posteriors look good
plot(mole_brm_int)

# Rhat values look like they are very close to 1
bayesplot::mcmc_rhat(rhat(mole_brm_int))

# No issues with autocorrelation here!
bayesplot::mcmc_acf(as.data.frame(mole_brm_int))

# Model assumptions
bayes_fit <- fitted(mole_brm_int) %>%  as.data.frame()
bayes_res <- residuals(mole_brm_int) %>%  as.data.frame()

# Doesn't seem like there is any relationship
qplot(bayes_fit$Estimate, bayes_res$Estimate)

# ok
pp_check(mole_brm_int, type = "scatter")

# A little off at the tails but otherwise ok
qqnorm(bayes_res$Estimate)
qqline(bayes_res$Estimate)

# but the error looks normal
pp_check(mole_brm_int, type = "error_hist")

# Chains fit to posterior and data well
pp_check(mole_brm_int, type = "stat_2d", test = c("mean", "sd"))
pp_check(mole_brm_int)

# Assumptions met

```


#### 3.2 Examine whether there is an interaction or not using LOO cross-validation. 
Is a model with an interaction more predictive?

```{r 3.2 CV}
# build LOO
mole_loo <- loo(mole_brm)
int_loo <- loo(mole_brm_int)

#compare
loo_compare(mole_loo, int_loo)

```

The model without the interaction is the better fit, as the intercept model has a lower elpd_diff and greater se_diff. There doesn't appear to be an interaction. 

#### 3.3 Compare the two castes energy expendeture at the meanlevel of log mass. 
Are they different? How would you discuss your conclusions.

```{r 3.3}
# BANOVA
mole_brm_em <- emmeans(mole_brm, ~lnmass + caste)
mole_brm_em

contrast(mole_brm_em, method = "tukey")
```

Yes the two castes differ at the mean mass. The estimated mean for each caste falls outside of the 95% credible interval, making it highly unlikely that the groups overlap in energy when stratified by weight. 


#### 3.4 Plot the fit model.
Use tidybayes and ggdist with your model to show fit and credible intervals with the raw data points on top. modelr::data.grid() might help as well.

```{r 3.4 plotting}
# plot distribution of posteriors with CIs 

contrast(mole_brm_em, method = "tukey") %>% 
  gather_emmeans_draws() %>% 
  ggplot(aes(x=.value, y = contrast)) +
  geom_halfeyeh()


```


